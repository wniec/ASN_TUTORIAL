{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5936ead-f150-44e5-a122-645185d159f2",
   "metadata": {},
   "source": [
    "# NEAT - NeuroEvolution of Augmenting Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cfc69-a09c-41ec-b11f-28fbda2cdc92",
   "metadata": {},
   "source": [
    "## Motivation and idea\n",
    "\n",
    "Most neural networks are trained using gradient-based optimization like backpropagation. This approach requires:\n",
    "- Differentiable activation functions,\n",
    "- Continuous loss functions,\n",
    "- Fixed network topology.\n",
    "\n",
    "Many problems, especially those involving control, sparse or delayed rewards, or discrete decision-making like some reinforcement learning problems make gradient-based training difficult or unstable.\n",
    "\n",
    "Neuroevolution offers an alternative: instead of adjusting weights using gradients, we treat the entire network as an individual in a population and proceed to evole the population (network topologies, weights or both) using standard principles of genetic algorithms - selection, crossover, mutations.\n",
    "\n",
    "In essence, instead of optimizing the netwarks using calculus we search for good networks using a genetic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248cb2c-15cf-44d5-8706-e4f79ee8e51f",
   "metadata": {},
   "source": [
    "## NEAT\n",
    "\n",
    "NEAT is a neuroevolution algorithm designed to evolve both weights and topology of the network introduced by Kenneth O. Stanley & Risto Miikkulainen in their paper [Efficient Evolution of Neural Network Topologies](https://nn.cs.utexas.edu/downloads/papers/stanley.cec02.pdf).\n",
    "\n",
    "NEAT works by maintaining a popolation of neural networks, each with its own topology and weights. These networks are evaluated on a given task, assigned a fitness score and then selectively bred through crossover and mutation to form the next generation of networks.\n",
    "\n",
    "The key ideas that make NEAT different compared to standard genetic algorithms or other neuroevolution algorithms are historical markings, where every new topological innovation receives a unique innovation number, making it possible to align different network topologies during crossover without confusion, and the idea to protect innovation, i.e maintaining diversity by letting newly mutated networks have time to prove their worth by only comparing them within their own species before competing globally.\n",
    "\n",
    "### Genotype representation in NEAT\n",
    "\n",
    "Each netowrk in NEAT can be represented as a genotype containing a list of node genes and connection genes. Node genes containing information about network nodes, connection genes containing information about connectins such as input node, output node, connection weight.\n",
    "\n",
    "<center><img src=\"./images/genotype.png\"/></center>\n",
    "\n",
    "The mapping from genotype to phenotype is deterministic: every gene precisely defines how the corresponding network will be structured and behave.\n",
    "\n",
    "### Historical markings (innovation numbers) and crossover\n",
    "\n",
    "A central concept that makes NEAT efficient and stable during evolution is its system of historical markings. These numbers serve as a unique record of how each structural feature of a network came into existence.\n",
    "\n",
    "When a new structural mutation occurs NEAT assigns it a new innovation number. This number acts like a genetic timestamp that records the order of discovery for every new connection gene.\n",
    "\n",
    "Without innovation numbers, it would be difficult to align genes between two parent networks during crossover, especially when their topologies differ. NEAT uses innovation numbers to ensure that corresponding genes from different genomes can be matched correctly, even if the networks have evolved independently for many generations.\n",
    "\n",
    "--------------\n",
    "\n",
    "When two genomes reproduce, NEAT aligns their genes using innovation numbers. Genes are classified as:\n",
    "- Matching: present in both parents (same innovation ID).\n",
    "- Disjoint: present in one parent but missing in the middle of the other’s innovation range.\n",
    "- Excess: present in one parent but beyond the other’s maximum innovation ID.\n",
    "\n",
    "The offspring inherits matching genes randomly and nonmatching genes from the fitter parent. This preserves meaningful structure during crossover, even when networks differ in size or shape.\n",
    "\n",
    "For example:\n",
    "<center><img src=\"images/markings.png\"/></center>\n",
    "Here, although Parent 1 and Parent 2 look different, their innovation numbers (shown at the top of each gene) tell us which genes match up with which without the need for topological analysis.\n",
    "\n",
    "### Mutations\n",
    "\n",
    "Mutation in NEAT can change both connection weights and network structures. \n",
    "\n",
    "Connection weights mutate as in any NE system, with each connection either perturbed or not.\n",
    "$$ w' = w + \\mathcal{N}(0, \\sigma^{2}) $$\n",
    "\n",
    "Structural mutations, which expand the genome, occur in two ways:\n",
    "- In the add connection mutation, a single new connection gene is added connecting two previously unconnected nodes <center><img src=\"images/add_connection.png\"/></center>\n",
    "- In the add node mutation an existing connection is split and the new node placed where the old connection used to be. The old connection is disabled and two new connections are added to the genome. <center><img src=\"images/add_node.png\"/></center>\n",
    "\n",
    "### Speciation and compatibility distance\n",
    "\n",
    "To prevent new, innovative structures from being immediately outcompeted by older, optimized ones, NEAT groups similar genomes into species. Within a species, individuals compete only with each other.\n",
    "\n",
    "Similarity is measured by compatibility distance:\n",
    "\n",
    "$$ \\delta(g_{a}, g_{b}) = \\frac{c_{1}E(g_{a}, g_{b})}{N} + \\frac{c_{2}D(g_{a}, g_{b})}{N} + c_{3}\\overline{W}(g_{a}, g_{b}) $$\n",
    "\n",
    "Where:\n",
    "- $E(g_{a}, g_{b})$ - Excess genes\n",
    "- $D(g_{a}, g_{b})$ - Disjoint genes\n",
    "- $\\overline{W}(g_{a}, g_{b})$ - average weight difference of matching genes\n",
    "- $N$ - Number of genes in the larger genome\n",
    "- $c_{1}, c_{2}, c_{3}$ - importance factors\n",
    "\n",
    "Two networks belong to the same species if $\\delta < \\delta_{threshold}$. Every genome is placed into the first species for which this condition is satisfied, so that no network can belong to two different species.\n",
    "\n",
    "\n",
    "The size of each species is determined by comparing averge fitness of the species compared to global population fitness, i.e at each step the size of given species is determined by the following formula:\n",
    "\n",
    "$$ N'_{j} = \\frac{\\sum_{i=1}^{N_{j}}f_{ij}}{f} $$\n",
    "\n",
    "Where:\n",
    "- $N_{j}$ and $N'_{j}$ are the old and new number of individuals in species j\n",
    "- $f_{ij}$ is the adjusted fitness of individual $i$ in species $j$\n",
    "- $f$ is the mean adjusted fitness in the entire population\n",
    "\n",
    "During crossover the best performing $r\\%$ of each species is randomly mated to generate $N'_{j}$ offspring, which replaces the entire population of the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb77bc3-47e0-4c21-ba15-0bd1d575333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import neat\n",
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310d030-d240-4c4a-a1b9-9477cd7c587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.25, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, edgecolors=\"k\", label=\"Train\"\n",
    ")\n",
    "plt.scatter(\n",
    "    X_test_scaled[:, 0], X_test_scaled[:, 1], c=y_test, marker=\"x\", s=80, label=\"Test\"\n",
    ")\n",
    "plt.title(\"Two Moons Dataset (Standardized)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training set shape: X={X_train_scaled.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set shape: X={X_test_scaled.shape}, y={y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064bbf3-674f-492b-a270-9ccc7d44c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(nn_output: np.ndarray, true_data: np.ndarray) -> np.ndarray:\n",
    "    accuracy = (nn_output == true_data).astype(float).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861dc305-2fef-44e2-be0c-2fbe0309cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        outputs = np.array([net.activate(x)[0] > 0.5 for x in X_train]).astype(int)\n",
    "        genome.fitness = fitness_function(outputs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf21e7a-0ca1-40a9-ac84-6f863cbe9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config_filename):\n",
    "    # Load configuration.\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation, config_filename)\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    p = neat.Population(config)\n",
    "\n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5))\n",
    "\n",
    "    # Run for up to 300 generations.\n",
    "    winner = p.run(eval_genomes, 300)\n",
    "\n",
    "    # Display the winning genome.\n",
    "    print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "    # Show output of the most fit genome against training data.\n",
    "    print('\\nOutput:')\n",
    "    winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "    for xi, xo in zip(X_test, y_test):\n",
    "        output = winner_net.activate(xi)\n",
    "        print(\"input {!r}, expected output {!r}, got {!r}\".format(xi, xo, output))\n",
    "\n",
    "    p = neat.Checkpointer.restore_checkpoint('neat-checkpoint-4')\n",
    "    p.run(eval_genomes, 10)\n",
    "    return winner, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d01a72-6373-4a48-969d-f970e2d4a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner, stats = run('config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b116f03-8790-46de-9f5e-c2c4201ced47",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation, 'config')\n",
    "node_names = {-1: 'x', -2: 'y'}\n",
    "visualize.draw_net(config, winner, True, node_names=node_names)\n",
    "\n",
    "visualize.plot_stats(stats, ylog=False, view=True)\n",
    "\n",
    "visualize.plot_species(stats, view=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a836de1-b3ac-4762-a495-8723de703d03",
   "metadata": {},
   "source": [
    "# Reinforcement learning examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f209de2-5609-433e-ac74-645165ef9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm\n",
    "import neat\n",
    "import visualize\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "from IPython.display import Image, SVG, display\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2da09d-b681-4bec-8fec-fa6e2b7db7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config, env, run_with_single_net_f):\n",
    "    for genome_id, genome in genomes:\n",
    "        eval_env = copy.deepcopy(env)\n",
    "        eval_env.reset()\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        genome.fitness = run_with_single_net_f(net, eval_env)\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707658fc-63f4-4b78-a6fd-ff545807edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config_filename, env_name, eval_function, output_dir, checkpoint=None) -> None:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation, config_filename)\n",
    "    \n",
    "    if checkpoint:\n",
    "        print(f\"Restoring from checkpoint: {checkpoint}\")\n",
    "        p = neat.Checkpointer.restore_checkpoint(checkpoint)\n",
    "    else:\n",
    "        p = neat.Population(config)\n",
    "    \n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(5, filename_prefix=os.path.join(output_dir, 'neat-checkpoint-')))\n",
    "    \n",
    "    winner = p.run(lambda g, c: eval_genomes(g, c, env_name, eval_function), 200)\n",
    "    \n",
    "    print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "    \n",
    "    with open(f\"{output_dir}/winner_genome.pkl\", \"wb\") as f:\n",
    "        pickle.dump(winner, f)\n",
    "    \n",
    "    visualize.draw_net(config, winner, view=False, filename=os.path.join(output_dir, 'best_network'))\n",
    "    visualize.plot_stats(stats, ylog=False, view=False, filename=os.path.join(output_dir, 'fitness_progress.svg'))\n",
    "    visualize.plot_species(stats, view=False, filename=os.path.join(output_dir, 'species_evolution.svg'))\n",
    "    \n",
    "    print(f\"results saved in '{output_dir}' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa69b1-1820-4fc2-a4cb-b186a95e13f1",
   "metadata": {},
   "source": [
    "## CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238ecce-f1ad-4225-81a5-64a449bb2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_single_net_cartpole(net: Any, environment, max_steps=5000, N_EXPERIMENTS = 10):\n",
    "    reward_sum = 0.0\n",
    "\n",
    "    for _ in range(N_EXPERIMENTS):\n",
    "        done = False\n",
    "        state, info = environment.reset()\n",
    "        step = 0\n",
    "        while not done:\n",
    "            output = net.activate(state)\n",
    "            action = max(enumerate(output), key=lambda x: x[1])[0]\n",
    "            state, reward, done, truncated, info = environment.step(action)\n",
    "            step += 1\n",
    "            reward_sum += reward\n",
    "            if step >= max_steps:\n",
    "                break\n",
    "                \n",
    "    return reward_sum / N_EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f350ffe-19cd-48e7-9c68-099785a15400",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode=None)\n",
    "main(\"config_cartpole\", env, run_with_single_net_cartpole, output_dir = \"reinforcement/cartpole\", checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcfa0e-ad2c-4939-b315-9c14b501bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"cartpole\"\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/best_network.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/fitness_progress.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/species_evolution.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56067915-4e65-4d40-aae0-7896a490f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=f\"images/cartpole_plot.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811d9ba-c80d-4730-8d67-686a0b8ea8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=f\"images/cartpole_net1.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0675441-32b7-4986-aacd-c9da4bb4cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reinforcement/cartpole/winner_genome.pkl\", \"rb\") as f:\n",
    "    winner = pickle.load(f)\n",
    "\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    \"config_cartpole\"\n",
    ")\n",
    "\n",
    "net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='human')\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "step = 0\n",
    "while not done:\n",
    "    env.render()\n",
    "    output = net.activate(state)\n",
    "    action = max(enumerate(output), key=lambda x: x[1])[0]\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    step += 1\n",
    "    if step >= 500:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de1b7c-38a5-41b2-bdae-d1c4a78d75b6",
   "metadata": {},
   "source": [
    "## Lunar lander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905819b-e5aa-47e4-8f53-1cc4b0faf9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_with_single_net_lander(net: Any, environment, max_steps=5000, N_EXPERIMENTS = 10):\n",
    "    reward_sum = 0.0\n",
    "\n",
    "    for _ in range(N_EXPERIMENTS):\n",
    "        done = False\n",
    "        state, info = environment.reset()\n",
    "        step = 0\n",
    "        while not done:\n",
    "            output = net.activate(state)\n",
    "            action = max(enumerate(output), key=lambda x: x[1])[0]\n",
    "            state, reward, done, truncated, info = environment.step(action)\n",
    "            step += 1\n",
    "            reward_sum += reward\n",
    "            if step >= max_steps or reward < -200:\n",
    "                break\n",
    "\n",
    "    return reward_sum / N_EXPERIMENTS\n",
    "\n",
    "env = gym.make('LunarLander-v3', enable_wind=True, render_mode=None)\n",
    "main(\"config_lunar_lander\", env, run_with_single_net_lander, output_dir = \"reinforcement/lander\", checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb535c-96ef-4bf5-8ab6-bbc2aab4c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"lander\"\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/best_network.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/fitness_progress.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/species_evolution.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30c53e-fde6-4400-a351-d3bc1f243084",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reinforcement/lander/winner_genome.pkl\", \"rb\") as f:\n",
    "    winner = pickle.load(f)\n",
    "\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    \"config_lunar_lander\"\n",
    ")\n",
    "\n",
    "net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "env = gym.make('LunarLander-v3', enable_wind=True, render_mode='human')\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    output = net.activate(state)\n",
    "    action = max(enumerate(output), key=lambda x: x[1])[0]\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2edb0-8079-4f22-a202-e2c99b0ac6a3",
   "metadata": {},
   "source": [
    "## lunar lander continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5d214-1a78-4746-8a4d-87ea9630a257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_with_single_net_lander_cont(net: Any, environment, max_steps=5000, N_EXPERIMENTS = 4):\n",
    "    reward_sum = 0.0\n",
    "\n",
    "    for _ in range(N_EXPERIMENTS):\n",
    "        done = False\n",
    "        state, info = environment.reset()\n",
    "        step = 0\n",
    "        while not done:\n",
    "            output = net.activate(state)\n",
    "            action = np.clip(output, -1.0, 1.0)\n",
    "            state, reward, done, truncated, info = environment.step(action)\n",
    "            step += 1\n",
    "            reward_sum += reward\n",
    "            if step >= max_steps or reward < -200:\n",
    "                break\n",
    "\n",
    "    return reward_sum / N_EXPERIMENTS\n",
    "    \n",
    "env = gym.make('LunarLander-v3', enable_wind=True, continuous=True, render_mode=None)\n",
    "main(\"config_lunar_lander\", env, run_with_single_net_lander_cont, output_dir = \"reinforcement/lander_cont\", checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e1270-ffd7-4af8-b14b-639862b3ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"lander_cont\"\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/best_network.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/fitness_progress.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/species_evolution.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfafdd-4ac9-433c-b982-add3a20867f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reinforcement/lander_cont/winner_genome.pkl\", \"rb\") as f:\n",
    "    winner = pickle.load(f)\n",
    "\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    \"config_lunar_lander\"\n",
    ")\n",
    "\n",
    "net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "env = gym.make('LunarLander-v3', continuous=True, render_mode='human')\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    output = net.activate(state)\n",
    "    action = np.clip(output, -1.0, 1.0)\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727ce24-b1ea-412d-a8b3-d58405880e62",
   "metadata": {},
   "source": [
    "## BipedalWalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c857aa-2bb1-4590-afff-7efd5892fd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EXPERIMENTS = 3\n",
    "OUTPUT_DIR = \"reinforcement/walker/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def run_with_single_net_walker(net: Any, environment, max_steps=2000, N_EXPERIMENTS = 3):\n",
    "    reward_sum = 0.0\n",
    "\n",
    "    for _ in range(N_EXPERIMENTS):\n",
    "        done = False\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        state, info = environment.reset()\n",
    "        step = 0\n",
    "        while not (done or terminated or truncated):\n",
    "            output = net.activate(state)\n",
    "            action = np.clip(output, -1.0, 1.0)\n",
    "            state, reward, terminated, truncated, info = environment.step(action)\n",
    "            step += 1\n",
    "            reward_sum += reward\n",
    "            if step >= max_steps or reward < -200:\n",
    "                break\n",
    "                \n",
    "    return reward_sum / N_EXPERIMENTS\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=None)\n",
    "main(\"config_walker\", env checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b6019-db7e-4920-93a0-ffed8d9c40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"walker\"\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/best_network.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/fitness_progress.svg\"))\n",
    "display(SVG(filename=f\"reinforcement/{env_name}/species_evolution.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0063e2-d710-444b-88aa-7798ebd665c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reinforcement/walker/winner_genome.pkl\", \"rb\") as f:\n",
    "    winner = pickle.load(f)\n",
    "\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    \"config_walker\"\n",
    ")\n",
    "\n",
    "net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    output = net.activate(state)\n",
    "    action = np.clip(output, -1.0, 1.0)\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
